{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras \n",
    "from keras.layers import Input, Dense,Conv2D,MaxPooling2D,BatchNormalization,Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "def load_dataset():\n",
    "    df=pd.read_csv(\"/home/aditya_girish_pawate/Documents/Projects/Digit Recognizer/train.csv\")\n",
    "    arr=df.to_numpy()\n",
    "    np.random.shuffle(arr)\n",
    "    arr1=arr[:,1:]\n",
    "    arr2s=arr[:,0]\n",
    "    arr2 = to_categorical(arr2s, num_classes=10)\n",
    "    arr1.shape\n",
    "    arr1=arr1.reshape(-1,28,28,1)\n",
    "    arr2=arr2.reshape(-1,10)\n",
    "    x_train=arr1[:40000]\n",
    "    y_train=arr2[:40000]\n",
    "    x_dev=arr1[40000:]\n",
    "    y_dev=arr2[40000:]\n",
    "    return x_train,y_train,x_dev,y_dev\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,y_train,x_dev,y_dev=load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l1\n",
    "# instantiate regularizer\n",
    "reg = l1(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model1(shape):\n",
    "    \n",
    "    inputs1=Input((shape),name='i1')\n",
    "    X=Conv2D(filters=32,kernel_size=(3,3),strides=(1,1))(inputs1)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(X)\n",
    "    X=Conv2D(filters=64,kernel_size=(2,2),strides=(1,1))(inputs1)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(X)\n",
    "    X=Conv2D(filters=128,kernel_size=(2,2),strides=(1,1))(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(X)\n",
    "    X=Conv2D(filters=256,kernel_size=(2,2),strides=(1,1))(inputs1)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=MaxPooling2D(pool_size=(2,2), strides=None, padding='valid')(X)\n",
    "    X=Conv2D(filters=512,kernel_size=(2,2),strides=(1,1))(X)\n",
    "    X=BatchNormalization()(X)\n",
    "    X=Flatten()(X)\n",
    "    X=Dense(1024,activation='relu',kernel_regularizer=reg)(X)\n",
    "    X=Dense(10,activation='softmax')(X)\n",
    "       \n",
    "    model=keras.models.Model( inputs=inputs1, outputs= X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model1([28,28,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,y_train,batch_size=512,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 1s 692us/step\n",
      "Loss = 1.8329040565490722\n",
      "Accuracy On Dev Set = 0.9775000214576721\n"
     ]
    }
   ],
   "source": [
    "preds = model.evaluate(x_dev,y_dev)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Accuracy On Dev Set = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2=pd.read_csv(\"/home/aditya_girish_pawate/Documents/Projects/Digit Recognizer/test.csv\")\n",
    "arr=df2.to_numpy()\n",
    "arr=arr.reshape(-1,28,28,1)\n",
    "x_test=arr\n",
    "y_preds = model.predict(x_test)\n",
    "y_pred=np.argmax(y_preds,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "final={'Imageld':list(range(1,len(x_test)+1)),'Label':list(y_pred)}\n",
    "df1=pd.DataFrame(final,columns=['ImageId','Label'])\n",
    "df1.to_csv (r'/home/aditya_girish_pawate/Documents/Projects/Digit Recognizer/Predictions.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
